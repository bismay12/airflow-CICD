steps:

# - Airflow Env variables.
substitutions:
  _COMPOSER_REGION: asia-south1
  _COMPOSER_ENV_NAME: airflow-cicd1
  _ROLLBACK: 'false'
  _SEVERITY: MEDIUM
  _SEVERITY1: HIGH
  _SEVERITY2: CRITICAL
  
# Access the id_github file from Secret Manager, and setup SSH
steps:
  - name: 'gcr.io/cloud-builders/git'
    secretEnv: ['SSH_KEY']
    entrypoint: 'bash'
    args:
    - -c
    - |
      echo "$$SSH_KEY" >> /root/.ssh/id_rsa
      chmod 400 /root/.ssh/id_rsa
      ssh-keyscan -t rsa github.com > known_hosts.github
      cp known_hosts.github /root/.ssh/known_hosts
# cat known_hosts.github 
    volumes:
    - name: 'ssh'
      path: /root/.ssh
  
# Clone the repository
  - name: 'gcr.io/cloud-builders/git'
    args:
    - clone
    - git@github.com:bismay12/sonar-test.git
    volumes:
    - name: 'ssh'
      path: /root/.ssh
      
  # install dependencies
  - name: python:3.8-slim
    entrypoint: pip
    args: ["install", "-r", "requirements.txt", "-c", "constraints.txt", "--user"]

  - name: python:3.8-slim
    entrypoint: pip
    args: ["install", "-r", "requirements-test.txt", "--user"]

  # run in python 3.8 which is latest version in Cloud Composer
  - name: python:3.8-slim
    entrypoint: python3.8
    args: ["-m", "pytest", "-s", "dags/",'--cov=dags','--cov=utils','--cov-report=xml','-v']

  # install dependencies
  - name: python
    entrypoint: pip
    args: ["install", "-r", "utils/requirements.txt", "--user"]    

  # Static code Analysis
  - name: 'gcr.io/$PROJECT_ID/sonar-scanner:latest'
    args:
    - '-Dsonar.host.url=http://35.244.55.55:9000/ '
    - '-Dsonar.login=sqp_78d4c4d00e71fc99a703f80d38fee3b6618ee95a'
    - '-Dsonar.projectKey=sonar-test-1 '
    - '-Dsonar.sources=.'
    - '-Dsonar.python.coverage.reportPaths=coverage.xml'

  
# Build the image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/niveustraining/airflow-image:v1.0', '.']

  - id: scan
    name: gcr.io/cloud-builders/gcloud
    entrypoint: /bin/bash
    args:
     - -c
     - |
       gcloud artifacts docker images scan 'gcr.io/niveustraining/airflow-image:v1.0' \
       --format='value(response.scan)' > /workspace/docdags/scan_id.txt
       
  - id: severity Critical
    name: gcr.io/cloud-builders/gcloud
    entrypoint: /bin/bash
    args:
     - -c
     - | 
       gcloud artifacts docker images list-vulnerabilities \
        $(cat /workspace/docdags/scan_id.txt) --format='value(vulnerability.effectiveSeverity)' \
        | if grep -Fxq $_SEVERITY2 
          then echo 'Failed vulnerability check - CRITICAL'
          exit 1 
          fi
          
  - id: severity High
    name: gcr.io/cloud-builders/gcloud
    entrypoint: /bin/bash
    args:
     - -c
     - | 
       gcloud artifacts docker images list-vulnerabilities \
        $(cat /workspace/docdags/scan_id.txt) --format='value(vulnerability.effectiveSeverity)' \
        | if grep -Fxq $_SEVERITY1
          then echo 'Failed vulnerability check - HIGH'
          exit 1 
          fi
  - id: severity Medium
    name: gcr.io/cloud-builders/gcloud
    entrypoint: /bin/bash
    args:
     - -c
     - | 
       gcloud artifacts docker images list-vulnerabilities \
        $(cat /workspace/docdags/scan_id.txt) --format='value(vulnerability.effectiveSeverity)' \
        | if grep -Fxq $_SEVERITY 
          then echo 'Failed vulnerability check - MEDIUM'
          exit 1 
          fi
    
# Push the image to GCR
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/niveustraining/airflow-image:v1.0']

# vulnerability scan

  - name: 'gcr.io/cloud-builders/gcloud'
    args: ['beta', 'container', 'images', 'describe', 'gcr.io/niveustraining/airflow-image:v1.0', '--format=json']

# Removing the old build Dags object
  - name: 'gcr.io/cloud-builders/gsutil'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gsutil -m rm -r gs://asia-south1-airflow-cicd1-99651280-bucket/dags/*
  
# Pull the Older Image and get the previous dags
  - name: gcr.io/niveustraining/airflow-image:v1.0
    entrypoint: /bin/bash
    args:
    - -c
    - |
      if [ "$_ROLLBACK" != "false" ]
      then
        cp -rv /dags/*  /workspace/docdags/
      fi
 # Condational Logic for Rollback and Dag updates
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
    - -c
    - |
     if [ "$_ROLLBACK" != "true" ]
     then
       echo "ROLLBACK NOT REQUIRED"
       for dagfile in $(ls dags)
             do
            gcloud composer environments storage dags import \
            --environment $_COMPOSER_ENV_NAME \
            --location $_COMPOSER_REGION \
            --source dags/$$dagfile
            done
     fi
     
     if [ "$_ROLLBACK" != "false" ]
     then
       echo "ROLLBACK In PROGRESS"
       for dagfile in $(ls /workspace/docdags)
       do
            gcloud composer environments storage dags import \
            --environment $_COMPOSER_ENV_NAME \
            --location $_COMPOSER_REGION \
            --source /workspace/docdags/$$dagfile
       done
     fi
  
availableSecrets:
    secretManager:
    - versionName: projects/866354246469/secrets/dataflow-cicd/versions/latest
      env: 'SSH_KEY'
